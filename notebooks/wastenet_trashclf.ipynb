{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "T7z19-hvpg32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "caf3ea45-7cf0-491b-ffb6-6f13ec94e246"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'WasteNet'...\n",
            "remote: Enumerating objects: 23, done.\u001b[K\n",
            "remote: Counting objects: 100% (23/23), done.\u001b[K\n",
            "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
            "remote: Total 23 (delta 7), reused 9 (delta 1), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (23/23), 10.63 KiB | 5.31 MiB/s, done.\n",
            "Resolving deltas: 100% (7/7), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/sleepingcat4/WasteNet.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/InhumanlyInsane/trashnet-clf.git\n",
        "!pip install -r trashnet-clf/requirements.txt\n",
        "!python trashnet-clf/dataset_collection.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7XnYXKnq-PL",
        "outputId": "079e4ae1-65d9-4d27-ccf6-7cd87f5ee748"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'trashnet-clf'...\n",
            "remote: Enumerating objects: 35, done.\u001b[K\n",
            "remote: Counting objects: 100% (35/35), done.\u001b[K\n",
            "remote: Compressing objects: 100% (23/23), done.\u001b[K\n",
            "remote: Total 35 (delta 13), reused 27 (delta 8), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (35/35), 15.68 KiB | 15.68 MiB/s, done.\n",
            "Resolving deltas: 100% (13/13), done.\n",
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.10/dist-packages (from -r trashnet-clf/requirements.txt (line 1)) (1.4.20)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from -r trashnet-clf/requirements.txt (line 2)) (4.10.0.84)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from -r trashnet-clf/requirements.txt (line 3)) (0.27.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r trashnet-clf/requirements.txt (line 4)) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from -r trashnet-clf/requirements.txt (line 5)) (0.20.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r trashnet-clf/requirements.txt (line 6)) (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from -r trashnet-clf/requirements.txt (line 7)) (2.2.2)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (from -r trashnet-clf/requirements.txt (line 8)) (0.19.1)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from albumentations->-r trashnet-clf/requirements.txt (line 1)) (1.13.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from albumentations->-r trashnet-clf/requirements.txt (line 1)) (6.0.2)\n",
            "Requirement already satisfied: pydantic>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from albumentations->-r trashnet-clf/requirements.txt (line 1)) (2.10.3)\n",
            "Requirement already satisfied: albucore==0.0.19 in /usr/local/lib/python3.10/dist-packages (from albumentations->-r trashnet-clf/requirements.txt (line 1)) (0.0.19)\n",
            "Requirement already satisfied: eval-type-backport in /usr/local/lib/python3.10/dist-packages (from albumentations->-r trashnet-clf/requirements.txt (line 1)) (0.2.0)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.10/dist-packages (from albumentations->-r trashnet-clf/requirements.txt (line 1)) (4.10.0.84)\n",
            "Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.10/dist-packages (from albucore==0.0.19->albumentations->-r trashnet-clf/requirements.txt (line 1)) (3.11.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->-r trashnet-clf/requirements.txt (line 3)) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->-r trashnet-clf/requirements.txt (line 3)) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->-r trashnet-clf/requirements.txt (line 3)) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->-r trashnet-clf/requirements.txt (line 3)) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->-r trashnet-clf/requirements.txt (line 3)) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->-r trashnet-clf/requirements.txt (line 3)) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r trashnet-clf/requirements.txt (line 4)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r trashnet-clf/requirements.txt (line 4)) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->-r trashnet-clf/requirements.txt (line 4)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->-r trashnet-clf/requirements.txt (line 4)) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->-r trashnet-clf/requirements.txt (line 5)) (11.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->-r trashnet-clf/requirements.txt (line 7)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r trashnet-clf/requirements.txt (line 7)) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->-r trashnet-clf/requirements.txt (line 7)) (2024.2)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb->-r trashnet-clf/requirements.txt (line 8)) (8.1.7)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r trashnet-clf/requirements.txt (line 8)) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r trashnet-clf/requirements.txt (line 8)) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb->-r trashnet-clf/requirements.txt (line 8)) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r trashnet-clf/requirements.txt (line 8)) (4.25.5)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r trashnet-clf/requirements.txt (line 8)) (5.9.5)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r trashnet-clf/requirements.txt (line 8)) (2.19.2)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb->-r trashnet-clf/requirements.txt (line 8)) (1.3.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb->-r trashnet-clf/requirements.txt (line 8)) (75.1.0)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb->-r trashnet-clf/requirements.txt (line 8)) (1.17.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->-r trashnet-clf/requirements.txt (line 8)) (4.0.11)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations->-r trashnet-clf/requirements.txt (line 1)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations->-r trashnet-clf/requirements.txt (line 1)) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->-r trashnet-clf/requirements.txt (line 3)) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->-r trashnet-clf/requirements.txt (line 3)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->-r trashnet-clf/requirements.txt (line 3)) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->-r trashnet-clf/requirements.txt (line 3)) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->-r trashnet-clf/requirements.txt (line 4)) (3.0.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r trashnet-clf/requirements.txt (line 8)) (5.0.1)\n",
            "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 1.4.23 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n",
            "dataset-resized.zip: 100% 42.8M/42.8M [00:00<00:00, 186MB/s]\n",
            "Augmenting glass class images 1 times each...\n",
            "100% 400/400 [00:05<00:00, 69.09it/s]\n",
            "Augmenting cardboard class images 1 times each...\n",
            "100% 322/322 [00:05<00:00, 58.48it/s]\n",
            "Augmenting metal class images 1 times each...\n",
            "100% 328/328 [00:04<00:00, 70.37it/s]\n",
            "Augmenting plastic class images 1 times each...\n",
            "100% 385/385 [00:05<00:00, 64.51it/s]\n",
            "Balanced data augmentation completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "Rqm7Q_OBxiZO",
        "outputId": "b4df0db3-b2d9-463a-8b64-f4eaa121e888"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "yQ1WzW4pp-xO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(data_dir):\n",
        "   class_map = {'cardboard': 0, 'glass': 1, 'metal': 2, 'paper': 3, 'plastic': 4}\n",
        "\n",
        "   x_train, y_train = [], []\n",
        "   x_val, y_val = [], []\n",
        "\n",
        "   # Process training data\n",
        "   for class_name in class_map:\n",
        "       train_path = os.path.join(data_dir, 'train', class_name)\n",
        "       for img_name in os.listdir(train_path):\n",
        "           img_path = os.path.join(train_path, img_name)\n",
        "           img = cv2.imread(img_path, cv2.IMREAD_ANYDEPTH)\n",
        "           img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "           x_train.append(img)\n",
        "           y_train.append(class_map[class_name])\n",
        "\n",
        "       # Process validation data\n",
        "       val_path = os.path.join(data_dir, 'val', class_name)\n",
        "       for img_name in os.listdir(val_path):\n",
        "           img_path = os.path.join(val_path, img_name)\n",
        "           img = cv2.imread(img_path, cv2.IMREAD_ANYDEPTH)\n",
        "           img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "           x_val.append(img)\n",
        "           y_val.append(class_map[class_name])\n",
        "\n",
        "   return (np.array(x_train), np.array(y_train)), (np.array(x_val), np.array(y_val))\n",
        "\n",
        "# Create arrays\n",
        "(x_train, y_train), (x_val, y_val) = create_dataset('./data-main')"
      ],
      "metadata": {
        "id": "n695ejqPrK6H"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 5\n",
        "y_train = to_categorical(y_train, num_classes)\n",
        "y_val = to_categorical(y_val, num_classes)\n",
        "\n",
        "# Define the input shape for the feature extractor\n",
        "input_shape = x_train.shape[1:]\n",
        "# Define the learning rates for fine-tuning\n",
        "learning_rates = [0.001, 0.001, 0.0001]"
      ],
      "metadata": {
        "id": "n0Nl8g6BsS9J"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.densenet import DenseNet121\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "class WandbMetricsCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        wandb.log({\n",
        "            \"accuracy\": logs['accuracy'],\n",
        "            \"val_accuracy\": logs['val_accuracy'],\n",
        "            \"loss\": logs['loss'],\n",
        "            \"val_loss\": logs['val_loss'],\n",
        "            \"epoch\": epoch\n",
        "        })\n",
        "\n",
        "class FeatureExtractorFineTuner:\n",
        "    def __init__(self, input_shape, num_classes, learning_rates):\n",
        "        self.input_shape = input_shape\n",
        "        self.num_classes = num_classes\n",
        "        self.learning_rates = learning_rates\n",
        "        self.feature_extractor = self.create_feature_extractor()\n",
        "        self.fine_tuning_started = False\n",
        "\n",
        "    def create_feature_extractor(self):\n",
        "        # Load the DenseNet model pre-trained on ImageNet\n",
        "        base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=self.input_shape)\n",
        "\n",
        "        # Freeze the convolutional layer blocks and flatten layer\n",
        "        for layer in base_model.layers:\n",
        "            if 'conv' in layer.name or 'pool' in layer.name or 'flatten' in layer.name:\n",
        "                layer.trainable = False\n",
        "\n",
        "        # Get the output of the last convolutional layer\n",
        "        output = base_model.output\n",
        "\n",
        "        # Add a global average pooling layer\n",
        "        output = tf.keras.layers.GlobalAveragePooling2D()(output)\n",
        "\n",
        "        # Add a fully connected layer with softmax activation for classification\n",
        "        output = tf.keras.layers.Dense(self.num_classes, activation='softmax')(output)\n",
        "\n",
        "        # Create the feature extraction model\n",
        "        feature_extractor = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "        return feature_extractor\n",
        "\n",
        "    def fine_tune_model(self):\n",
        "        # Get the total number of layers in the model\n",
        "        num_layers = len(self.feature_extractor.layers)\n",
        "\n",
        "        # Create a list of optimizers with different learning rates for each layer\n",
        "        optimizers = [SGD(learning_rate=lr) for lr in self.learning_rates]\n",
        "\n",
        "        # Set the optimizers for each layer\n",
        "        for i, optimizer in enumerate(optimizers):\n",
        "            self.feature_extractor.layers[i].trainable = True\n",
        "\n",
        "        # Compile the model with the final learning rate\n",
        "        self.feature_extractor.compile(optimizer=optimizers[-1], loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    def train(self, train_data, train_labels, val_data, val_labels, epochs=10):\n",
        "        wandb.init(project=\"WasteNet Classification\")\n",
        "        wandb.config.update({\n",
        "            \"learning_rates\": self.learning_rates,\n",
        "            \"epochs\": epochs,\n",
        "            \"architecture\": \"DenseNet121\"\n",
        "        })\n",
        "\n",
        "        checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
        "            'best_model.keras',\n",
        "            monitor='val_accuracy',\n",
        "            save_best_only=True,\n",
        "            mode='max'\n",
        "        )\n",
        "\n",
        "        if not self.fine_tuning_started:\n",
        "            optimizer = SGD(learning_rate=self.learning_rates[0])\n",
        "            self.feature_extractor.compile(optimizer=optimizer,\n",
        "                                          loss='categorical_crossentropy',\n",
        "                                          metrics=['accuracy'])\n",
        "\n",
        "            history = self.feature_extractor.fit(\n",
        "                train_data, train_labels,\n",
        "                epochs=epochs,\n",
        "                validation_data=(val_data, val_labels),\n",
        "                callbacks=[checkpoint, WandbMetricsCallback()]\n",
        "            )\n",
        "\n",
        "            accuracy = history.history['accuracy'][-1]\n",
        "            if 0.6 <= accuracy <= 0.7:\n",
        "                self.fine_tune_model()\n",
        "                self.fine_tuning_started = True\n",
        "                wandb.log({\"fine_tuning_started\": True})\n",
        "        else:\n",
        "            optimizer = SGD(learning_rate=self.learning_rates[-1])\n",
        "            self.feature_extractor.compile(optimizer=optimizer,\n",
        "                                          loss='categorical_crossentropy',\n",
        "                                          metrics=['accuracy'])\n",
        "\n",
        "            history = self.feature_extractor.fit(\n",
        "                train_data, train_labels,\n",
        "                epochs=epochs,\n",
        "                validation_data=(val_data, val_labels),\n",
        "                callbacks=[checkpoint, WandbMetricsCallback()]\n",
        "            )\n",
        "\n",
        "        wandb.finish()"
      ],
      "metadata": {
        "id": "W-JJq5qrxSoF"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of FeatureExtractorFineTuner\n",
        "extractor_fine_tuner = FeatureExtractorFineTuner(input_shape, num_classes, learning_rates)\n",
        "# Train the model\n",
        "extractor_fine_tuner.train(x_train, y_train, x_val, y_val, epochs=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3TnyC86duboE",
        "outputId": "f1ae8047-d040-4d0c-ba5b-2dcdafe26acf"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241221_165017-s5zaorm1</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/soyokaze83-universitas-indonesia/WasteNet%20Classification/runs/s5zaorm1' target=\"_blank\">lyric-cherry-5</a></strong> to <a href='https://wandb.ai/soyokaze83-universitas-indonesia/WasteNet%20Classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/soyokaze83-universitas-indonesia/WasteNet%20Classification' target=\"_blank\">https://wandb.ai/soyokaze83-universitas-indonesia/WasteNet%20Classification</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/soyokaze83-universitas-indonesia/WasteNet%20Classification/runs/s5zaorm1' target=\"_blank\">https://wandb.ai/soyokaze83-universitas-indonesia/WasteNet%20Classification/runs/s5zaorm1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 446ms/step - accuracy: 0.2453 - loss: 1.6220 - val_accuracy: 0.2875 - val_loss: 1.5999\n",
            "Epoch 2/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 306ms/step - accuracy: 0.3602 - loss: 1.4746 - val_accuracy: 0.3562 - val_loss: 1.4948\n",
            "Epoch 3/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 313ms/step - accuracy: 0.3803 - loss: 1.4063 - val_accuracy: 0.4083 - val_loss: 1.4265\n",
            "Epoch 4/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 316ms/step - accuracy: 0.4108 - loss: 1.3768 - val_accuracy: 0.4187 - val_loss: 1.4067\n",
            "Epoch 5/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 316ms/step - accuracy: 0.4324 - loss: 1.3398 - val_accuracy: 0.4375 - val_loss: 1.3610\n",
            "Epoch 6/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 298ms/step - accuracy: 0.4584 - loss: 1.3132 - val_accuracy: 0.4354 - val_loss: 1.3428\n",
            "Epoch 7/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 314ms/step - accuracy: 0.4641 - loss: 1.2955 - val_accuracy: 0.4563 - val_loss: 1.3403\n",
            "Epoch 8/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 305ms/step - accuracy: 0.4529 - loss: 1.2854 - val_accuracy: 0.4812 - val_loss: 1.3179\n",
            "Epoch 9/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 295ms/step - accuracy: 0.4831 - loss: 1.2605 - val_accuracy: 0.4604 - val_loss: 1.3218\n",
            "Epoch 10/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 302ms/step - accuracy: 0.4847 - loss: 1.2532 - val_accuracy: 0.5042 - val_loss: 1.2937\n",
            "Epoch 11/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 303ms/step - accuracy: 0.4581 - loss: 1.2507 - val_accuracy: 0.5083 - val_loss: 1.2719\n",
            "Epoch 12/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 305ms/step - accuracy: 0.5097 - loss: 1.2064 - val_accuracy: 0.5083 - val_loss: 1.2782\n",
            "Epoch 13/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 314ms/step - accuracy: 0.5042 - loss: 1.2171 - val_accuracy: 0.5104 - val_loss: 1.2579\n",
            "Epoch 14/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 316ms/step - accuracy: 0.5021 - loss: 1.2134 - val_accuracy: 0.5229 - val_loss: 1.2413\n",
            "Epoch 15/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 305ms/step - accuracy: 0.5007 - loss: 1.2033 - val_accuracy: 0.5083 - val_loss: 1.2454\n",
            "Epoch 16/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 300ms/step - accuracy: 0.5175 - loss: 1.1882 - val_accuracy: 0.5208 - val_loss: 1.2414\n",
            "Epoch 17/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 300ms/step - accuracy: 0.5120 - loss: 1.1781 - val_accuracy: 0.5292 - val_loss: 1.2265\n",
            "Epoch 18/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 298ms/step - accuracy: 0.5159 - loss: 1.1686 - val_accuracy: 0.5208 - val_loss: 1.2181\n",
            "Epoch 19/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 294ms/step - accuracy: 0.5268 - loss: 1.1556 - val_accuracy: 0.5208 - val_loss: 1.2137\n",
            "Epoch 20/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 324ms/step - accuracy: 0.5272 - loss: 1.1677 - val_accuracy: 0.5396 - val_loss: 1.2071\n",
            "Epoch 21/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 307ms/step - accuracy: 0.5454 - loss: 1.1286 - val_accuracy: 0.5188 - val_loss: 1.2174\n",
            "Epoch 22/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 307ms/step - accuracy: 0.5422 - loss: 1.1357 - val_accuracy: 0.5312 - val_loss: 1.2035\n",
            "Epoch 23/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - accuracy: 0.5465 - loss: 1.1389Epoch 24/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 304ms/step - accuracy: 0.5255 - loss: 1.1399 - val_accuracy: 0.5625 - val_loss: 1.1756\n",
            "Epoch 25/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 294ms/step - accuracy: 0.5470 - loss: 1.1393 - val_accuracy: 0.5417 - val_loss: 1.1878\n",
            "Epoch 26/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 307ms/step - accuracy: 0.5423 - loss: 1.1239 - val_accuracy: 0.5250 - val_loss: 1.1864\n",
            "Epoch 27/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 308ms/step - accuracy: 0.5682 - loss: 1.1081 - val_accuracy: 0.5604 - val_loss: 1.1748\n",
            "Epoch 28/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 295ms/step - accuracy: 0.5629 - loss: 1.1138 - val_accuracy: 0.5583 - val_loss: 1.1628\n",
            "Epoch 29/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 306ms/step - accuracy: 0.5654 - loss: 1.1018 - val_accuracy: 0.5479 - val_loss: 1.1704\n",
            "Epoch 30/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 302ms/step - accuracy: 0.5615 - loss: 1.1030 - val_accuracy: 0.5729 - val_loss: 1.1496\n",
            "Epoch 31/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 307ms/step - accuracy: 0.5677 - loss: 1.0971 - val_accuracy: 0.5688 - val_loss: 1.1550\n",
            "Epoch 32/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 314ms/step - accuracy: 0.5699 - loss: 1.0889 - val_accuracy: 0.5750 - val_loss: 1.1431\n",
            "Epoch 33/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 316ms/step - accuracy: 0.5845 - loss: 1.0819 - val_accuracy: 0.5813 - val_loss: 1.1447\n",
            "Epoch 34/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 298ms/step - accuracy: 0.5773 - loss: 1.0737 - val_accuracy: 0.5792 - val_loss: 1.1333\n",
            "Epoch 35/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 291ms/step - accuracy: 0.5845 - loss: 1.0602 - val_accuracy: 0.5813 - val_loss: 1.1373\n",
            "Epoch 36/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 297ms/step - accuracy: 0.5757 - loss: 1.0735 - val_accuracy: 0.5771 - val_loss: 1.1362\n",
            "Epoch 37/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 300ms/step - accuracy: 0.5811 - loss: 1.0529 - val_accuracy: 0.5833 - val_loss: 1.1321\n",
            "Epoch 38/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 308ms/step - accuracy: 0.5762 - loss: 1.0614 - val_accuracy: 0.5771 - val_loss: 1.1334\n",
            "Epoch 39/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 312ms/step - accuracy: 0.5829 - loss: 1.0798 - val_accuracy: 0.5854 - val_loss: 1.1305\n",
            "Epoch 40/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 309ms/step - accuracy: 0.5879 - loss: 1.0598 - val_accuracy: 0.5792 - val_loss: 1.1234\n",
            "Epoch 41/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 305ms/step - accuracy: 0.5697 - loss: 1.0508 - val_accuracy: 0.5792 - val_loss: 1.1187\n",
            "Epoch 42/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 317ms/step - accuracy: 0.5832 - loss: 1.0585 - val_accuracy: 0.5938 - val_loss: 1.1168\n",
            "Epoch 43/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 305ms/step - accuracy: 0.5911 - loss: 1.0353 - val_accuracy: 0.5875 - val_loss: 1.1141\n",
            "Epoch 44/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 306ms/step - accuracy: 0.6005 - loss: 1.0322 - val_accuracy: 0.5688 - val_loss: 1.1253\n",
            "Epoch 45/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 293ms/step - accuracy: 0.5953 - loss: 1.0305 - val_accuracy: 0.5917 - val_loss: 1.1076\n",
            "Epoch 46/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 312ms/step - accuracy: 0.5959 - loss: 1.0416 - val_accuracy: 0.5854 - val_loss: 1.1052\n",
            "Epoch 47/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 290ms/step - accuracy: 0.5890 - loss: 1.0429 - val_accuracy: 0.5854 - val_loss: 1.1047\n",
            "Epoch 48/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 321ms/step - accuracy: 0.6061 - loss: 1.0397 - val_accuracy: 0.5958 - val_loss: 1.0937\n",
            "Epoch 49/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 316ms/step - accuracy: 0.6083 - loss: 1.0114 - val_accuracy: 0.6146 - val_loss: 1.0882\n",
            "Epoch 50/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 307ms/step - accuracy: 0.5965 - loss: 1.0473 - val_accuracy: 0.5896 - val_loss: 1.0998\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▂▃▃▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>loss</td><td>█▇▆▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▃▄▄▄▅▅▅▆▆▆▆▆▆▆▆▇▆▇▇▇▆▇▇▇███████████████</td></tr><tr><td>val_loss</td><td>█▇▆▅▅▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.60478</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>fine_tuning_started</td><td>True</td></tr><tr><td>loss</td><td>1.02351</td></tr><tr><td>val_accuracy</td><td>0.58958</td></tr><tr><td>val_loss</td><td>1.09976</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">lyric-cherry-5</strong> at: <a href='https://wandb.ai/soyokaze83-universitas-indonesia/WasteNet%20Classification/runs/s5zaorm1' target=\"_blank\">https://wandb.ai/soyokaze83-universitas-indonesia/WasteNet%20Classification/runs/s5zaorm1</a><br> View project at: <a href='https://wandb.ai/soyokaze83-universitas-indonesia/WasteNet%20Classification' target=\"_blank\">https://wandb.ai/soyokaze83-universitas-indonesia/WasteNet%20Classification</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241221_165017-s5zaorm1/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a2JPQpq8ux1c"
      },
      "execution_count": 8,
      "outputs": []
    }
  ]
}